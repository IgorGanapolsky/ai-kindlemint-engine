name: PR Validation Pipeline

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Quick checks that should fail fast
  quick-checks:
    name: Quick Validation Checks
    runs-on: ubuntu-latest
    if: github.event.pull_request.draft == false
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Check PR Size
      uses: actions/github-script@v7
      with:
        script: |
          const pr = context.payload.pull_request;
          const { additions, deletions, changed_files } = pr;
          
          // Warn if PR is too large
          if (additions + deletions > 1000) {
            core.warning(`PR is large: ${additions + deletions} lines changed. Consider breaking into smaller PRs.`);
          }
          
          if (changed_files > 50) {
            core.setFailed(`PR changes too many files: ${changed_files}. Maximum recommended: 50`);
          }
          
    - name: Validate Branch Name
      run: |
        branch_name="${{ github.head_ref }}"
        if ! echo "$branch_name" | grep -E '^(feature|fix|hotfix|chore|release|exp)/.*$'; then
          echo "❌ Invalid branch name: $branch_name"
          echo "Expected format: feature/*, fix/*, hotfix/*, chore/*, release/*, exp/*"
          exit 1
        fi
        
    - name: Check Commit Messages
      run: |
        # Check if commits follow conventional format
        git log --format="%s" origin/main..HEAD | while read commit_msg; do
          if ! echo "$commit_msg" | grep -E '^(feat|fix|docs|style|refactor|perf|test|chore|build|ci)(\(.+\))?: .+$'; then
            echo "❌ Invalid commit message: $commit_msg"
            echo "Expected format: type(scope): description"
            exit 1
          fi
        done

  # Code quality and style checks
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    needs: quick-checks
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install black isort flake8 mypy pylint bandit
        pip install -r requirements.txt
        
    - name: Black Formatting Check
      run: black --check src/ scripts/ tests/
      
    - name: isort Import Order Check
      run: isort --check-only src/ scripts/ tests/
      
    - name: Flake8 Linting
      run: flake8 src/ scripts/ tests/ --max-line-length=120 --extend-ignore=E203,W503
      
    - name: MyPy Type Checking
      run: mypy src/ scripts/ --ignore-missing-imports
      
    - name: Pylint Code Analysis
      run: pylint src/ scripts/ --fail-under=8.0 || true
      
    - name: Security Scan with Bandit
      run: bandit -r src/ scripts/ -ll -f json -o bandit-report.json

  # Test execution
  test-suite:
    name: Test Suite
    runs-on: ubuntu-latest
    needs: quick-checks
    strategy:
      matrix:
        python-version: ['3.11', '3.12']
        
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-timeout pytest-xdist
        
    - name: Run Unit Tests
      run: |
        pytest tests/unit/ -v --cov=src/kindlemint --cov-report=xml --cov-report=html --timeout=300
        
    - name: Run Integration Tests
      run: |
        pytest tests/integration/ -v --timeout=600 || true
        
    - name: Upload Coverage
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        fail_ci_if_error: true
        
    - name: Check Coverage Threshold
      run: |
        coverage_percent=$(python -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage.xml'); root = tree.getroot(); print(float(root.attrib['line-rate']) * 100)")
        echo "Coverage: ${coverage_percent}%"
        if (( $(echo "$coverage_percent < 80" | bc -l) )); then
          echo "❌ Coverage below 80% threshold"
          exit 1
        fi

  # Critical business logic validation
  business-validation:
    name: Business Logic Validation
    runs-on: ubuntu-latest
    needs: quick-checks
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run Critical Metadata QA
      run: |
        python scripts/critical_metadata_qa.py
        
    - name: Validate Puzzle Generators
      run: |
        python -m pytest tests/validators/ -v
        
    - name: Check Book Production Pipeline
      run: |
        python scripts/validate_book_pipeline.py || echo "⚠️ Book pipeline validation needs attention"

  # Performance checks
  performance-checks:
    name: Performance Validation
    runs-on: ubuntu-latest
    needs: quick-checks
    continue-on-error: true
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark memory-profiler
        
    - name: Run Performance Benchmarks
      run: |
        pytest tests/performance/ --benchmark-only --benchmark-compare || true
        
    - name: Check Memory Usage
      run: |
        python scripts/memory_profiler.py || true

  # Documentation checks
  documentation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    needs: quick-checks
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Check README
      run: |
        if ! grep -q "## Getting Started" README.md; then
          echo "❌ README missing Getting Started section"
          exit 1
        fi
        
    - name: Validate Markdown
      uses: DavidAnson/markdownlint-cli2-action@v14
      with:
        globs: '**/*.md'
        config: '.markdownlint.json'
      continue-on-error: true
      
    - name: Check for Required Docs
      run: |
        required_docs=("README.md" "CLAUDE.md" "docs/ORCHESTRATION_ARCHITECTURE.md")
        for doc in "${required_docs[@]}"; do
          if [ ! -f "$doc" ]; then
            echo "❌ Missing required documentation: $doc"
            exit 1
          fi
        done

  # AI-powered review orchestration
  ai-review-orchestration:
    name: AI Review Orchestration
    runs-on: ubuntu-latest
    needs: [code-quality, test-suite]
    if: always()
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Trigger Sentry AI Review
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: '@sentry review'
          });
          
    - name: Trigger DeepSource Analysis
      run: |
        echo "DeepSource analysis will run automatically"
        
    - name: Consolidate AI Feedback
      uses: actions/github-script@v7
      with:
        script: |
          // Wait for AI reviews to complete
          await new Promise(resolve => setTimeout(resolve, 30000));
          
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            per_page: 100
          });
          
          const aiComments = comments.data.filter(c => 
            c.user.login.includes('sentry') || 
            c.user.login.includes('coderabbit') ||
            c.user.login.includes('deepsource')
          );
          
          console.log(`Found ${aiComments.length} AI review comments`);

  # Final status check
  pr-status:
    name: PR Status Summary
    runs-on: ubuntu-latest
    needs: [code-quality, test-suite, business-validation, documentation]
    if: always()
    
    steps:
    - name: Check Job Statuses
      uses: actions/github-script@v7
      with:
        script: |
          const jobStatuses = {
            codeQuality: '${{ needs.code-quality.result }}',
            tests: '${{ needs.test-suite.result }}',
            business: '${{ needs.business-validation.result }}',
            docs: '${{ needs.documentation.result }}'
          };
          
          let summary = '## PR Validation Summary\n\n';
          let hasFailures = false;
          
          for (const [job, status] of Object.entries(jobStatuses)) {
            const emoji = status === 'success' ? '✅' : '❌';
            summary += `${emoji} ${job}: ${status}\n`;
            if (status !== 'success') hasFailures = true;
          }
          
          // Update PR with status comment
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: summary
          });
          
          if (hasFailures) {
            core.setFailed('PR validation failed. See summary above.');
          }